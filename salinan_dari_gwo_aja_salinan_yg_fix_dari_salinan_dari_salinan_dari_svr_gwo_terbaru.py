# -*- coding: utf-8 -*-
"""Salinan_dari_GWO_AJA_Salinan_YG_FIX_dari_Salinan_dari_Salinan_dari_SVR_GWO_TERBARU.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IvyGChcHrAlpyBDznNKJOeQk4hFYU4fT
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import statsmodels.api as sm
from sklearn.svm import SVR
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score
from sklearn.model_selection import GridSearchCV, KFold, cross_val_score, learning_curve, train_test_split
from scipy.stats import chi2
from statsmodels.graphics.tsaplots import plot_pacf
from pandas.tseries.holiday import AbstractHolidayCalendar, Holiday, USFederalHolidayCalendar
from pandas.tseries.offsets import BDay
import plotly.express as px
import datetime
import time
import random
import warnings
warnings.filterwarnings('ignore')

# Set random seed untuk reproducibility
np.random.seed(42)
random.seed(42)

# =====================================================
# Input Data Penelitian
# =====================================================

# Load the dataset
url = 'https://raw.githubusercontent.com/dyahprimasarii/Data-Saham/refs/heads/main/Harga%20Penutupan%20ASII'
df = pd.read_csv(url)
print("Dataset Head:")
print(df.head())
print("\nDataset Info:")
print(df.info())

# Ubah tipe data kolom tanggal menjadi datetime
df['Date'] = pd.to_datetime(df['Date'], format='%d/%m/%Y')
print("\nDataset Info After Date Conversion:")
print(df.info())

# Visualisasi Time Series
fig = px.line(df, x="Date",
              y="Close",
              title='Harga Penutupan Saham ASII',
              labels={'Date': 'Tanggal', 'Close': 'Harga Penutupan'})
fig.show()

# =====================================================
# Deteksi Missing Value dan Analisis Deskriptif
# =====================================================

# Define function to get statistic descriptive for std population
def describe_pop(df):
    stats = {
       'count': len(df),
        'mean': np.mean(df),
        'std': np.std(df, ddof=0),  # standar deviasi populasi
        'min': np.min(df),
        'max': np.max(df),
        '25%': np.percentile(df, 25),
        '50%': np.percentile(df, 50),
        '75%': np.percentile(df, 75)
    }
    return pd.Series(stats).round(3)

# Display stat desc population
print("\nStatistik Deskriptif Close Price:")
print(describe_pop(df['Close']))

# Calculate the IQR for the 'Close' column
Q1 = df['Close'].quantile(0.25)
Q3 = df['Close'].quantile(0.75)
IQR = Q3 - Q1

# Define the outlier boundaries
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Identify the outliers
outliers = df[(df['Close'] < lower_bound) | (df['Close'] > upper_bound)]

# Print the outliers
print("\nOutliers:")
print(outliers)

# Visualize the outliers using a box plot
plt.figure(figsize=(8, 6))
plt.boxplot(df['Close'])
plt.title('Boxplot Close Price ASII')
plt.ylabel('Close Price (Rp)')
plt.show()

# Cek missing value
print("\nMissing Values:")
print(df.isnull().sum())

# Cek duplikasi
print(f"\nDuplikasi Data: {df.duplicated().sum()}")

# Menampilkan kurtosis dan skewness
print(f"\nKurtosis: {df['Close'].kurtosis().round(3)}")
print(f"Skewness: {df['Close'].skew().round(3)}")

# Plot distribusi data dengan histogram
fig = px.histogram(df, x="Close", nbins=20, title='Distribusi Close Price Saham ASII')
fig.update_layout(xaxis_title='Close Price (Rp)', yaxis_title='Frekuensi')
fig.show()

# Plot PACF
plt.figure(figsize=(12, 6))
plot_pacf(df['Close'], lags=30)
plt.title('Plot PACF')
plt.xlabel('Lag')
plt.ylabel('Korelasi')
plt.show()

# Membuat lag 1
df['lag1'] = df['Close'].shift(1)
print("\nData dengan Lag1:")
print(df.head())

# Drop missing values dari lag
df = df.dropna()

# Define variable
X = df[['lag1']].values
y = df['Close'].values

# Preprocessing data
def preprocess_data(data):
    # Deteksi missing value
    print("\nMissing value detection:")
    missing_values = data[['Close', 'lag1']].isnull().sum()
    print(missing_values)

    # Analisis deskriptif lengkap
    print("\nDescriptive statistics:")
    desc_stats = data[['Close', 'lag1']].describe()
    print(desc_stats)
    # Menambahkan varian ke statistik deskriptif
    desc_stats.loc['variance'] = data[['Close', 'lag1']].var()
    print(desc_stats)
    return data

data = preprocess_data(df)

# Standar deviasi dan koefisien variasi
print("\nStandar Deviasi:")
print(data[['Close', 'lag1']].std())

print("\nKoefisien Variasi (%):")
print((data[['Close', 'lag1']].std() /
       data[['Close', 'lag1']].mean()) * 100)

# =====================================================
# Pembagian Data Training dan Data Testing
# =====================================================

print("\n" + "="*60)
print("Tabel 13: Data Variabel Prediktor (X) dan Respon (Y)")
print("="*60)

# Buat dataframe untuk tabel
tabel_data = pd.DataFrame({
    'No': range(1, len(df) + 1),
    'X (t-1)': df['lag1'].values,
    'Y (t)': df['Close'].values
})

# Tampilkan 5 data pertama
print("\nData Awal (5 pertama):")
print(tabel_data.head().to_string(index=False))

# Tampilkan data tengah
tengah_idx = len(tabel_data) // 2
print("\nData Tengah:")
print(tabel_data.iloc[tengah_idx-2:tengah_idx+3].to_string(index=False))

# Tampilkan 5 data terakhir
print("\nData Akhir (5 terakhir):")
print(tabel_data.tail().to_string(index=False))

# Cek data asli sebelum lag
print("\n5 DATA TERAKHIR SEBELUM LAG:")
print(df[['Date', 'Close']].tail(10))

# Cek data setelah lag
print("\n5 DATA TERAKHIR SETELAH LAG:")
print(df[['Date', 'Close', 'lag1']].tail(10))

# Membagi dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=False)

def display_data(data, name):
    print(f"\n====== {name} ======")
    print(f"Shape: {data.shape}")
    print(pd.DataFrame(data[:5]).reset_index(drop=True))
    print("Data Akhir:")
    print(pd.DataFrame(data[-5:]).reset_index(drop=True))
    print(f"Total Data {name} = {len(data)}")

display_data(X_train, "X_train")
display_data(X_test, "X_test")
display_data(y_train, "y_train")
display_data(y_test, "y_test")

# Mendapatkan index untuk plotting
train_index = range(len(y_train))  # Index untuk data training
test_index = range(len(y_train), len(y_train) + len(y_test))  # Index untuk data testing

# Plot Time Series untuk Training dan Testing
plt.figure(figsize=(12, 6))
plt.plot(train_index, y_train, color='steelblue', linewidth=1.5, label='Training Data')
plt.plot(test_index, y_test, color='red', linewidth=1.5, label='Testing Data')
plt.title('Time Series Harga Saham (Train-Test Split)', fontsize=14, fontweight='bold')
plt.xlabel('Observasi')
plt.ylabel('Harga Saham')
plt.legend()
plt.grid(True, linestyle='--', alpha=0.7)
plt.tight_layout()
plt.savefig('plot_timeseries_train_test_split.png')
plt.show()

# =====================================================
# NORMALISASI DATA UNTUK GWO DAN MODEL LAINNYA
# =====================================================

# Initialize scalers
scaler_X = StandardScaler()  # ✓ Uppercase X (konsisten dengan X_train)
scaler_y = StandardScaler()  # ✓ Lowercase y (konsisten dengan y_train)

# Fit dan transform data training
X_train_scaled = scaler_X.fit_transform(X_train)  # ✓ scaler_X (uppercase)
y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1))  # ✓ scaler_y (lowercase)

# Transform data testing (hanya transform, tidak fit!)
X_test_scaled = scaler_X.transform(X_test)  # ✓ scaler_X (uppercase)
y_test_scaled = scaler_y.transform(y_test.reshape(-1, 1))  # ✓ Tambah reshape!

print(f"X_train_scaled shape: {X_train_scaled.shape}")
print(f"X_test_scaled shape: {X_test_scaled.shape}")
print(f"y_train_scaled shape: {y_train_scaled.shape}")
print(f"y_test_scaled shape: {y_test_scaled.shape}")

print("\nContoh data sebelum normalisasi:")
print(f"X_train[0]: {X_train[0]}")
print(f"y_train[0]: {y_train[0]}")

print("\nContoh data setelah normalisasi:")
print(f"X_train_scaled[0]: {X_train_scaled[0]}")
print(f"y_train_scaled[0]: {y_train_scaled[0]}")
print("="*60)

# =====================================================
# Uji Linearitas Terasvirta
# =====================================================

def terasvirta_test(X, y, alpha=0.05):
    y = np.array(y).flatten()
    X = np.array(X)

    # 1. Fit model linier
    X_sm = sm.add_constant(X)
    model_linear = sm.OLS(y, X_sm)
    results_linear = model_linear.fit() # Renamed to avoid confusion with the function's return value
    residuals = results_linear.resid
    fitted = results_linear.fittedvalues

    # 2. Regresi auxiliary
    X_test_aux = sm.add_constant(np.column_stack([X, fitted**2, fitted**3])) # Renamed to avoid confusion
    aux_model = sm.OLS(residuals**2, X_test_aux)
    aux_results = aux_model.fit()

    # 3. Hitung statistik uji dan p-value
    n = len(y)
    r_squared = aux_results.rsquared
    lm_statistic = n * r_squared
    df = 2
    p_value = 1 - chi2.cdf(lm_statistic, df)
    critical_value = chi2.ppf(1 - alpha, df)

   # 4. Kesimpulan
    conclusion = "Tolak H0 (Non-Linear)" if p_value < alpha else "Gagal Menolak H0 (Linear)"

    return {
        'LM Statistic': lm_statistic,
        'Degrees of Freedom': df,
        'p-value': p_value,
        'Critical Value': critical_value,
        'Conclusion': conclusion,
        'Regression Summary': aux_results.summary()
    }

# Uji Linearitas Terasvirta
print("\n=== Hasil Uji Linearitas Terasvirta ===")
results = terasvirta_test(X, y)

# Print hasil utama
for key, value in results.items():
    if key == 'Regression Summary':
        print(f"\n{key}:")
        print(value)
    else:
        print(f"{key}: {value}")

# Output:
print("\n=== Ringkasan Model Regresi Linear ===")
print(results['Regression Summary'])

# Kesimpulan Lengkap
if results['p-value'] < 0.05:
    print("\nKesimpulan lengkap:")
    print(f"Karena p-value ({results['p-value']:.10f}) < alpha (0.05), maka Tolak H0.")
    print("Artinya: Data bersifat NON-LINEAR, sehingga metode non-linear seperti SVR cocok digunakan.")
else:
    print("\nKesimpulan lengkap:")
    print(f"Karena p-value ({results['p-value']:.6f}) >= alpha (0.05), maka Gagal Menolak H0.")
    print("Artinya: Data bersifat LINEAR.")

# =====================================================
# Support Vector Regression Tanpa Optimasi (Default)
# =====================================================

def svr_without_optimization(X_train, y_train, X_test, y_test):
    # Parameter default
    C = 1.0
    epsilon = 0.1
    gamma = 'scale'

    # Initialize model
    model = SVR(kernel='rbf', C=C, epsilon=epsilon, gamma=gamma)

    # Training model
    model.fit(X_train, y_train)

    # Calculate actual gamma value when using 'scale'
    actual_gamma = 1 / (X_train.shape[1] * X_train.var()) if gamma == 'scale' else gamma

    # Get model parameters
    bias = model.intercept_[0]  # Bias term (b)
    dual_coefs = model.dual_coef_[0]  # Dual coefficients (β_i)

    # Predictions
    y_train_pred = model.predict(X_train)
    y_test_pred = model.predict(X_test)

    # Calculate MAPE
    mape_train_default = mean_absolute_percentage_error(y_train, y_train_pred) * 100
    mape_test_default = mean_absolute_percentage_error(y_test, y_test_pred) * 100

    # Print results
    print("\n" + "="*60)
    print("SVR WITHOUT OPTIMIZATION - EVALUATION RESULTS")
    print("="*60)
    print("Parameters used:")
    print(f"- C      : {C}")
    print(f"- Epsilon: {epsilon}")
    print(f"- Gamma  : {gamma} (actual value: {actual_gamma:.6f})")

    print("\nModel parameters:")
    print(f"- Bias term (b): {bias:.6f}")
    print(f"- Number of support vectors: {len(model.support_)}")

    print("\nDual Coefficients (β_i) Statistics:")
    print(f"- Range: [{dual_coefs.min():.6f}, {dual_coefs.max():.6f}]")
    print(f"- Sum: {dual_coefs.sum():.6f}")

    print("\nSample Dual Coefficients:")
    print(f"First 5 β_i values:", np.array2string(dual_coefs[:5], precision=6))

    mid_point = len(dual_coefs)//2
    print(f"Middle 5 β_i values:", np.array2string(dual_coefs[mid_point:mid_point+5], precision=6))
    print(f"Last 5 β_i values:", np.array2string(dual_coefs[-5:], precision=6))

    print("\nPerformance metrics:")
    print(f"MAPE Training Tanpa Optimasi (default) : {mape_train_default:.4f}%")
    print(f"MAPE Testing Tanpa Optimasi (default) : {mape_test_default:.4f}%")
    print("="*60)

    # Print actual vs predicted samples
    print("\nSample Actual vs Predicted Values (Testing):")
    test_comparison = pd.DataFrame({
        'Actual': y_test,
        'Predicted': y_test_pred
    })
    print("First 5 testing samples:")
    print(test_comparison.head())
    print("\nLast 5 testing samples:")
    print(test_comparison.tail())

    # Save results to Excel files
    train_results = pd.DataFrame({
        'Actual_Train': y_train,
        'Predicted_Train': y_train_pred
    })

    test_results = pd.DataFrame({
        'Actual_Test': y_test,
        'Predicted_Test': y_test_pred
    })

    with pd.ExcelWriter('svr_results_default.xlsx') as writer:
        train_results.to_excel(writer, sheet_name='Training Results', index=False)
        test_results.to_excel(writer, sheet_name='Testing Results', index=False)

    print("\nResults saved to 'svr_results_default.xlsx'")
    print("="*60)

    # Plot testing results
    plt.figure(figsize=(12, 6))
    plt.plot(test_comparison['Actual'], label='Actual', color='steelblue',
             marker='o', linewidth=2)
    plt.plot(test_comparison['Predicted'], label='Predicted (SVR)',
             color='red', linestyle='--', marker='x', linewidth=2)
    plt.title('Actual vs Predicted Values (SVR Without Optimization)',
              fontsize=14, fontweight='bold')
    plt.xlabel('Index')
    plt.ylabel('Target Value')
    plt.legend()
    plt.grid(True, linestyle='--', alpha=0.7)
    plt.tight_layout()
    plt.savefig('plot_svr_actual_vs_predicted_default.png')
    plt.show()

    return model, mape_train_default, mape_test_default

# Call the function
svr_model_default, mape_train_default, mape_test_default = svr_without_optimization(
    X_train, y_train, X_test, y_test
)

# =====================================================
# Support Vector Regression - Grey Wolf Optimizer
# =====================================================

def calculate_fitness(wolf_position, X_train_scaled, y_train_scaled, X_test_scaled, y_test_scaled):
    """
    Calculate fitness using SVR and MSE
    """
    try:
        svr = SVR(C=wolf_position[0],
                  epsilon=wolf_position[1],
                  gamma=wolf_position[2])
        svr.fit(X_train_scaled, y_train_scaled.ravel())
        y_pred = svr.predict(X_test_scaled)
        return mean_squared_error(y_test_scaled, y_pred)
    except:
        return float('inf')

def initialize_population(n_wolves, dim, bounds):
    """
    Initialize wolf population randomly within bounds
    """
    population = []
    for _ in range(n_wolves):
        position = []
        for d in range(dim):
            position.append(random.uniform(bounds[d][0], bounds[d][1]))
        population.append(position)
    return population

def update_position(current_pos, alpha_pos, beta_pos, delta_pos, a, bounds, dim):
    """
    Update position of wolf based on alpha, beta, and delta positions
    Following equations from Mirjalili et al. (2014)
    """
    new_position = []
    for d in range(dim):
        r1, r2 = random.random(), random.random()
        A1, A2, A3 = 2 * a * r1 - a, 2 * a * r1 - a, 2 * a * r1 - a
        C1, C2, C3 = 2 * r2, 2 * r2, 2 * r2

        D_alpha = abs(C1 * alpha_pos[d] - current_pos[d])
        D_beta = abs(C2 * beta_pos[d] - current_pos[d])
        D_delta = abs(C3 * delta_pos[d] - current_pos[d])

        X1 = alpha_pos[d] - A1 * D_alpha
        X2 = beta_pos[d] - A2 * D_beta
        X3 = delta_pos[d] - A3 * D_delta

        new_val = (X1 + X2 + X3) / 3
        new_val = max(bounds[d][0], min(bounds[d][1], new_val))
        new_position.append(new_val)
    return new_position

# =====================================================
# STEP 1: EVALUASI UKURAN POPULASI (LENGKAP)
# =====================================================
def evaluate_population_size_complete(X_train_scaled, y_train_scaled, X_test_scaled, y_test_scaled, scaler_y):
    """
    Evaluasi berbagai ukuran populasi wolves untuk menentukan popsize optimal
    """
    print("\n" + "="*80)
    print("LAMPIRAN 7: PENGUJIAN UKURAN POPULASI")
    print("="*80)

    dim = 3
    bounds = [(0.01, 100), (0, 1), (0.001, 100)]

    # Test dengan max_iter tetap (50)
    max_iter_test = 50
    popsize_options = [20, 30, 35, 40, 50]

    results = []
    all_params = []

    print("\nGWO Algorithm Overview:")
    print("-" * 80)
    print("# Grey Wolf Optimizer for SVR Hyperparameter Tuning")
    print("# Based on Mirjalili et al. (2014)")
    print()
    print("# Parameter bounds")
    print("bounds = [(0.01, 100), (0, 1), (0.001, 100)]  # C, epsilon, gamma")
    print()
    print("# Step 1: Initialize population")
    print("population = initialize_population(n_wolves, dim=3, bounds)")
    print()
    print("# Step 2: Evaluate fitness for each wolf")
    print("for wolf_position in population:")
    print("    fitness = calculate_fitness(wolf_position, X_train, y_train, X_test, y_test)")
    print()
    print("# Step 3: Identify alpha, beta, delta wolves (3 best solutions)")
    print("alpha_pos = best_wolf  # Lowest MSE")
    print("beta_pos = second_best")
    print("delta_pos = third_best")
    print()
    print("# Step 4: Update positions based on leaders")
    print("for iteration in range(max_iter):")
    print("    a = 2 - 2 * (iteration / max_iter)  # Decreases from 2 to 0")
    print("    for wolf in population:")
    print("        new_position = update_position(wolf, alpha, beta, delta, a, bounds)")
    print()
    print("# Step 5: Return best solution (alpha)")
    print("best_params = alpha_pos  # [C, epsilon, gamma]")
    print("-" * 80)

    for n_wolves in popsize_options:
        print(f"\n{'='*80}")
        print(f"Evaluating Population Size: {n_wolves}")
        print(f"{'='*80}")

        population = initialize_population(n_wolves, dim, bounds)

        alpha_pos, alpha_score = None, float('inf')
        beta_pos, beta_score = None, float('inf')
        delta_pos, delta_score = None, float('inf')

        convergence_history = []

        for iteration in range(max_iter_test):
            a = 2 - 2 * (iteration / max_iter_test)

            for pos in population:
                fitness = calculate_fitness(pos, X_train_scaled, y_train_scaled,
                                           X_test_scaled, y_test_scaled)

                if fitness < alpha_score:
                    delta_pos, delta_score = beta_pos, beta_score
                    beta_pos, beta_score = alpha_pos, alpha_score
                    alpha_pos, alpha_score = pos.copy(), fitness
                elif fitness < beta_score:
                    delta_pos, delta_score = beta_pos, beta_score
                    beta_pos, beta_score = pos.copy(), fitness
                elif fitness < delta_score:
                    delta_pos, delta_score = pos.copy(), fitness

            convergence_history.append(alpha_score)

            new_population = []
            for pos in population:
                new_pos = update_position(pos, alpha_pos, beta_pos, delta_pos, a, bounds, dim)
                new_population.append(new_pos)
            population = new_population

        # Hitung MAPE
        svr_temp = SVR(C=alpha_pos[0], epsilon=alpha_pos[1], gamma=alpha_pos[2])
        svr_temp.fit(X_train_scaled, y_train_scaled.ravel())
        y_pred_scaled = svr_temp.predict(X_test_scaled)
        y_pred_inv = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1))
        y_test_inv = scaler_y.inverse_transform(y_test_scaled)
        mape = mean_absolute_percentage_error(y_test_inv, y_pred_inv) * 100

        results.append({
            'Population': n_wolves,
            'Validation MAPE (%)': round(mape, 4),
            'Best Fitness': round(alpha_score, 8),
            'C': round(alpha_pos[0], 4),
            'Epsilon': round(alpha_pos[1], 4),
            'Gamma': round(alpha_pos[2], 4)
        })

        all_params.append({
            'popsize': n_wolves,
            'mape': mape,
            'fitness': alpha_score,
            'C': alpha_pos[0],
            'epsilon': alpha_pos[1],
            'gamma': alpha_pos[2],
            'convergence': convergence_history
        })

        print(f"\nBest Parameters Found:")
        print(f"  C        : {alpha_pos[0]:.6f}")
        print(f"  Epsilon  : {alpha_pos[1]:.6f}")
        print(f"  Gamma    : {alpha_pos[2]:.6f}")
        print(f"  Fitness  : {alpha_score:.8f}")
        print(f"  MAPE     : {mape:.4f}%")

    # TABEL HASIL EVALUASI POPSIZE
    print("\n" + "="*80)
    print("Output:")
    print("="*80)
    print("\nTABEL HASIL EVALUASI UKURAN POPULASI")
    print("-" * 80)
    results_df = pd.DataFrame(results)
    print(results_df.to_string(index=False))

    # Tentukan popsize terbaik
    best_result = min(all_params, key=lambda x: x['fitness'])

    print("\n" + "="*80)
    print("KESIMPULAN EVALUASI UKURAN POPULASI")
    print("="*80)
    print(f"Ukuran Populasi: {best_result['popsize']}")
    print(f"Validation MAPE (%): {best_result['mape']:.4f}")
    print(f"Best Fitness: {best_result['fitness']:.8f}")
    print(f"\nParameter Terbaik:")
    print(f"  C       : {best_result['C']:.6f}")
    print(f"  Epsilon : {best_result['epsilon']:.6f}")
    print(f"  Gamma   : {best_result['gamma']:.6f}")
    print(f"\nBerdasarkan Tabel di atas:")
    print(f"- Nilai fitness terbaik: {best_result['fitness']:.8f}")
    print(f"- MAPE terkecil: {best_result['mape']:.4f}%")
    print(f"- Popsize optimal yang digunakan: {best_result['popsize']}")
    print("="*80)

    # PLOT CONVERGENCE untuk semua popsize
    plt.figure(figsize=(12, 6))
    for param in all_params:
        plt.plot(range(1, len(param['convergence']) + 1),
                param['convergence'],
                marker='o',
                label=f"Popsize={param['popsize']}",
                linewidth=2)

    plt.xlabel('Iteration', fontsize=12, fontweight='bold')
    plt.ylabel('Best Fitness (MSE)', fontsize=12, fontweight='bold')
    plt.title('Convergence Curve - Population Size Evaluation',
              fontsize=14, fontweight='bold')
    plt.legend(loc='best')
    plt.grid(True, linestyle='--', alpha=0.7)
    plt.yscale('log')
    plt.tight_layout()
    plt.savefig('population_size_optimization.png', dpi=300, bbox_inches='tight')
    plt.show()

    print("\nPlot saved as 'population_size_optimization.png'")

    return best_result['popsize'], all_params

# =====================================================
# STEP 2: EVALUASI JUMLAH ITERASI (LENGKAP)
# =====================================================
def evaluate_max_iterations_complete(X_train_scaled, y_train_scaled, X_test_scaled, y_test_scaled,
                                    optimal_popsize, scaler_y):
    """
    Evaluasi berbagai jumlah iterasi dengan popsize optimal
    """
    print("\n" + "="*80)
    print("LAMPIRAN 8: PENGUJIAN JUMLAH ITERASI")
    print("="*80)

    dim = 3
    bounds = [(0.01, 100), (0, 1), (0.001, 100)]
    n_options = [50, 100, 150, 200, 300]

    results = []
    all_params = []

    print(f"\nMenggunakan Popsize Optimal: {optimal_popsize}")
    print(f"Menguji berbagai jumlah iterasi: {n_options}")
    print()

    for max_iter in n_options:
        print(f"\n{'='*80}")
        print(f"Evaluating Max Iterations: {max_iter}")
        print(f"{'='*80}")

        population = initialize_population(optimal_popsize, dim, bounds)

        alpha_pos, alpha_score = None, float('inf')
        beta_pos, beta_score = None, float('inf')
        delta_pos, delta_score = None, float('inf')

        convergence_history = []

        for iteration in range(max_iter):
            a = 2 - 2 * (iteration / max_iter)

            for pos in population:
                fitness = calculate_fitness(pos, X_train_scaled, y_train_scaled,
                                           X_test_scaled, y_test_scaled)

                if fitness < alpha_score:
                    delta_pos, delta_score = beta_pos, beta_score
                    beta_pos, beta_score = alpha_pos, alpha_score
                    alpha_pos, alpha_score = pos.copy(), fitness
                elif fitness < beta_score:
                    delta_pos, delta_score = beta_pos, beta_score
                    beta_pos, beta_score = pos.copy(), fitness
                elif fitness < delta_score:
                    delta_pos, delta_score = pos.copy(), fitness

            convergence_history.append(alpha_score)

            new_population = []
            for pos in population:
                new_pos = update_position(pos, alpha_pos, beta_pos, delta_pos, a, bounds, dim)
                new_population.append(new_pos)
            population = new_population

        # Hitung MAPE
        svr_temp = SVR(C=alpha_pos[0], epsilon=alpha_pos[1], gamma=alpha_pos[2])
        svr_temp.fit(X_train_scaled, y_train_scaled.ravel())
        y_pred_scaled = svr_temp.predict(X_test_scaled)
        y_pred_inv = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1))
        y_test_inv = scaler_y.inverse_transform(y_test_scaled)
        mape = mean_absolute_percentage_error(y_test_inv, y_pred_inv) * 100

        results.append({
            'N (Iterasi)': max_iter,
            'Validation MAPE (%)': round(mape, 4),
            'Best Fitness': round(alpha_score, 8),
            'C': round(alpha_pos[0], 4),
            'Epsilon': round(alpha_pos[1], 4),
            'Gamma': round(alpha_pos[2], 4)
        })

        all_params.append({
            'max_iter': max_iter,
            'mape': mape,
            'fitness': alpha_score,
            'C': alpha_pos[0],
            'epsilon': alpha_pos[1],
            'gamma': alpha_pos[2],
            'convergence': convergence_history
        })

        print(f"\nBest Parameters Found:")
        print(f"  C        : {alpha_pos[0]:.6f}")
        print(f"  Epsilon  : {alpha_pos[1]:.6f}")
        print(f"  Gamma    : {alpha_pos[2]:.6f}")
        print(f"  Fitness  : {alpha_score:.8f}")
        print(f"  MAPE     : {mape:.4f}%")

    # TABEL HASIL EVALUASI MAX_ITER
    print("\n" + "="*80)
    print("Output:")
    print("="*80)
    print("\nTABEL HASIL EVALUASI JUMLAH ITERASI")
    print("-" * 80)
    results_df = pd.DataFrame(results)
    print(results_df.to_string(index=False))

    # Tentukan max_iter terbaik
    best_result = min(all_params, key=lambda x: x['fitness'])

    print("\n" + "="*80)
    print("KESIMPULAN EVALUASI JUMLAH ITERASI")
    print("="*80)
    print(f"Jumlah Iterasi: {best_result['max_iter']}")
    print(f"Validation MAPE (%): {best_result['mape']:.4f}")
    print(f"Best Fitness: {best_result['fitness']:.8f}")
    print(f"\nParameter Terbaik:")
    print(f"  C       : {best_result['C']:.6f}")
    print(f"  Epsilon : {best_result['epsilon']:.6f}")
    print(f"  Gamma   : {best_result['gamma']:.6f}")
    print(f"\nBerdasarkan Tabel di atas:")
    print(f"- Nilai fitness terbaik: {best_result['fitness']:.8f}")
    print(f"- MAPE terkecil: {best_result['mape']:.4f}%")
    print(f"- Jumlah iterasi optimal yang digunakan: {best_result['max_iter']}")
    print("="*80)

    # PLOT CONVERGENCE untuk semua max_iter
    plt.figure(figsize=(12, 6))
    for param in all_params:
        plt.plot(range(1, len(param['convergence']) + 1),
                param['convergence'],
                marker='o',
                label=f"N={param['max_iter']}",
                linewidth=2)

    plt.xlabel('Iteration', fontsize=12, fontweight='bold')
    plt.ylabel('Best Fitness (MSE)', fontsize=12, fontweight='bold')
    plt.title(f'Convergence Curve - Max Iteration Evaluation (Popsize={optimal_popsize})',
              fontsize=14, fontweight='bold')
    plt.legend(loc='best')
    plt.grid(True, linestyle='--', alpha=0.7)
    plt.yscale('log')
    plt.tight_layout()
    plt.savefig('max_iteration_optimization.png', dpi=300, bbox_inches='tight')
    plt.show()

    print("\nPlot saved as 'max_iteration_optimization.png'")

    return best_result['max_iter'], all_params

# =====================================================
# STEP 3: OPTIMASI DENGAN PARAMETER OPTIMAL (LENGKAP)
# =====================================================
def grey_wolf_optimizer_final_complete(X_train_scaled, y_train_scaled, X_test_scaled, y_test_scaled,
                                      optimal_popsize, optimal_max_iter, scaler_y):
    """
    GWO dengan parameter optimal - OUTPUT LENGKAP
    """
    print("\n" + "="*80)
    print("LAMPIRAN 9: OPTIMASI GWO DENGAN PARAMETER OPTIMAL")
    print("="*80)
    print(f"\nParameter yang Digunakan:")
    print(f"  Popsize  : {optimal_popsize}")
    print(f"  Max Iter : {optimal_max_iter}")
    print("="*80)

    dim = 3
    bounds = [(0.01, 100), (0, 1), (0.001, 100)]

    start_time = time.time()

    population = initialize_population(optimal_popsize, dim, bounds)

    alpha_pos, alpha_score = None, float('inf')
    beta_pos, beta_score = None, float('inf')
    delta_pos, delta_score = None, float('inf')

    convergence_curve = []

    print("\nProses Optimasi GWO:")
    print("-" * 80)
    for iteration in range(optimal_max_iter):
        a = 2 - 2 * (iteration / optimal_max_iter)

        for pos in population:
            fitness = calculate_fitness(pos, X_train_scaled, y_train_scaled,
                                       X_test_scaled, y_test_scaled)

            if fitness < alpha_score:
                delta_pos, delta_score = beta_pos, beta_score
                beta_pos, beta_score = alpha_pos, alpha_score
                alpha_pos, alpha_score = pos.copy(), fitness
            elif fitness < beta_score:
                delta_pos, delta_score = beta_pos, beta_score
                beta_pos, beta_score = pos.copy(), fitness
            elif fitness < delta_score:
                delta_pos, delta_score = pos.copy(), fitness

        convergence_curve.append(alpha_score)

        new_population = []
        for pos in population:
            new_pos = update_position(pos, alpha_pos, beta_pos, delta_pos, a, bounds, dim)
            new_population.append(new_pos)
        population = new_population

        if (iteration + 1) % 10 == 0 or iteration == 0:
            print(f"Iterasi {iteration + 1:3d}/{optimal_max_iter} | Best Fitness (MSE): {alpha_score:.8f}")

    runtime = time.time() - start_time

    # Hitung MAPE final
    svr_final = SVR(C=alpha_pos[0], epsilon=alpha_pos[1], gamma=alpha_pos[2])
    svr_final.fit(X_train_scaled, y_train_scaled.ravel())
    y_pred_scaled = svr_final.predict(X_test_scaled)
    y_pred_inv = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1))
    y_test_inv = scaler_y.inverse_transform(y_test_scaled)
    mape_final = mean_absolute_percentage_error(y_test_inv, y_pred_inv) * 100

    # OUTPUT LENGKAP
    print("\n" + "="*80)
    print("Output:")
    print("="*80)
    print("\nHASIL OPTIMASI GWO")
    print("-" * 80)
    print(f"Best GWO Parameters:")
    print(f"  Population Size : {optimal_popsize}")
    print(f"  Max Iterations  : {optimal_max_iter}")
    print(f"  Runtime         : {runtime:.3f} seconds")
    print(f"\nBest SVR Hyperparameters:")
    print(f"  C       : {alpha_pos[0]:.6f}")
    print(f"  Epsilon : {alpha_pos[1]:.6f}")
    print(f"  Gamma   : {alpha_pos[2]:.6f}")
    print(f"\nPerformance Metrics:")
    print(f"  Best Fitness (MSE) : {alpha_score:.8f}")
    print(f"  Validation MAPE    : {mape_final:.4f}%")
    print("="*80)

    # TABEL PARAMETER OPTIMAL
    print("\n" + "="*80)
    print("TABEL WOLF OPTIMAL (ALPHA)")
    print("="*80)
    optimal_params_df = pd.DataFrame({
        'Parameter': ['C', 'Epsilon', 'Gamma', 'Fitness (MSE)', 'MAPE (%)'],
        'Value': [
            f"{alpha_pos[0]:.6f}",
            f"{alpha_pos[1]:.6f}",
            f"{alpha_pos[2]:.6f}",
            f"{alpha_score:.8f}",
            f"{mape_final:.4f}"
        ]
    })
    print(optimal_params_df.to_string(index=False))
    print("="*80)

    # PLOT CONVERGENCE CURVE
    plt.figure(figsize=(10, 6))
    plt.plot(range(1, len(convergence_curve) + 1), convergence_curve,
             'b-', linewidth=2, marker='o', markersize=4)
    plt.xlabel('Iteration', fontsize=12, fontweight='bold')
    plt.ylabel('Best Fitness (MSE)', fontsize=12, fontweight='bold')
    plt.title(f'GWO Convergence Curve\n(Popsize={optimal_popsize}, MaxIter={optimal_max_iter})',
              fontsize=14, fontweight='bold')
    plt.grid(True, linestyle='--', alpha=0.7)
    plt.yscale('log')
    plt.tight_layout()
    plt.savefig('gwo_convergence_final.png', dpi=300, bbox_inches='tight')
    plt.show()

    print("\nConvergence curve saved as 'gwo_convergence_final.png'")

    return alpha_pos, alpha_score, runtime, convergence_curve, mape_final

# =====================================================
# EKSEKUSI LENGKAP
# =====================================================
print("\n" + "="*80)
print("PEMBENTUKAN MODEL PADA DATA TRAINING (SVR-GWO)")
print("="*80)

# STEP 1: Evaluasi Ukuran Populasi
optimal_popsize, popsize_results = evaluate_population_size_complete(
    X_train_scaled, y_train_scaled, X_test_scaled, y_test_scaled, scaler_y
)

# STEP 2: Evaluasi Jumlah Iterasi
optimal_max_iter, iteration_results = evaluate_max_iterations_complete(
    X_train_scaled, y_train_scaled, X_test_scaled, y_test_scaled,
    optimal_popsize, scaler_y
)

# STEP 3: Run GWO dengan parameter optimal
best_solution, best_fitness, runtime, convergence, mape_gwo_final = grey_wolf_optimizer_final_complete(
    X_train_scaled, y_train_scaled, X_test_scaled, y_test_scaled,
    optimal_popsize, optimal_max_iter, scaler_y
)

# FIT MODEL FINAL
model_gwo = SVR(C=best_solution[0], epsilon=best_solution[1], gamma=best_solution[2])
model_gwo.fit(X_train_scaled, y_train_scaled.ravel())

print("\n" + "="*80)
print("PROSES SVR-GWO SELESAI! ✓")
print("="*80)

# =====================================================
# FIT MODEL FINAL DENGAN BEST PARAMETERS
# =====================================================
print("\n" + "="*80)
print("TRAINING MODEL SVR DENGAN HYPERPARAMETER OPTIMAL DARI GWO")
print("="*80)

model_gwo = SVR(C=best_solution[0],
                epsilon=best_solution[1],
                gamma=best_solution[2])
model_gwo.fit(X_train_scaled, y_train_scaled.ravel())

# Get model parameters
bias_gwo = model_gwo.intercept_
beta_gwo = model_gwo.dual_coef_
support_vectors_gwo = model_gwo.support_vectors_

print(f"\nModel Parameters:")
print(f"  Bias (b)                  : {bias_gwo[0]:.6f}")
print(f"  Number of Support Vectors : {len(model_gwo.support_)}")
print(f"  Dual Coefficients Range   : [{beta_gwo[0].min():.6f}, {beta_gwo[0].max():.6f}]")
print("="*80)

# =====================================================
# BETA COEFFICIENT ANALYSIS (DETAIL)
# =====================================================
print("\n" + "="*80)
print("BETA COEFFICIENT (β_i) ANALYSIS - SVR-GWO")
print("="*80)

# Ekstrak dual coefficients
dual_coefs_gwo = model_gwo.dual_coef_[0]  # Shape: (n_support_vectors,)

print("\nBeta Coefficients (β_i) Statistics:")
print("-" * 80)
print(f"Number of Support Vectors    : {len(model_gwo.support_)}")
print(f"Number of Beta Coefficients  : {len(dual_coefs_gwo)}")
print(f"Range of β_i                 : [{dual_coefs_gwo.min():.6f}, {dual_coefs_gwo.max():.6f}]")
print(f"Sum of β_i                   : {dual_coefs_gwo.sum():.6f}")
print(f"Mean of β_i                  : {dual_coefs_gwo.mean():.6f}")
print(f"Std Dev of β_i               : {dual_coefs_gwo.std():.6f}")

# Count positive and negative coefficients
n_positive = np.sum(dual_coefs_gwo > 0)
n_negative = np.sum(dual_coefs_gwo < 0)
print(f"\nPositive β_i count           : {n_positive}")
print(f"Negative β_i count           : {n_negative}")

print("\n" + "="*80)
print("BETA COEFFICIENT (β_i) SAMPLES")
print("="*80)

# First 5 beta coefficients
print("\nFirst 5 of beta coefficients:")
for i in range(min(5, len(dual_coefs_gwo))):
    print(f"  β_{i+1:3d} = {dual_coefs_gwo[i]:>12.6f}")

# Middle 5 beta coefficients
mid_point = len(dual_coefs_gwo) // 2
print(f"\nMiddle 5 of beta coefficients (around index {mid_point}):")
for i in range(mid_point, min(mid_point + 5, len(dual_coefs_gwo))):
    print(f"  β_{i+1:3d} = {dual_coefs_gwo[i]:>12.6f}")

# Last 5 beta coefficients
print(f"\nLast 5 of beta coefficients:")
start_idx = max(0, len(dual_coefs_gwo) - 5)
for i in range(start_idx, len(dual_coefs_gwo)):
    print(f"  β_{i+1:3d} = {dual_coefs_gwo[i]:>12.6f}")

print("\n" + "="*80)
print("BETA COEFFICIENT DISTRIBUTION VISUALIZATION")
print("="*80)

# Create histogram of beta coefficients
plt.figure(figsize=(12, 5))

# Subplot 1: Histogram
plt.subplot(1, 2, 1)
plt.hist(dual_coefs_gwo, bins=50, color='steelblue', edgecolor='black', alpha=0.7)
plt.xlabel('Beta Coefficient Value', fontsize=11, fontweight='bold')
plt.ylabel('Frequency', fontsize=11, fontweight='bold')
plt.title('Distribution of Beta Coefficients (β_i)', fontsize=12, fontweight='bold')
plt.axvline(x=0, color='red', linestyle='--', linewidth=2, label='Zero line')
plt.legend()
plt.grid(True, linestyle='--', alpha=0.5)

# Subplot 2: Scatter plot
plt.subplot(1, 2, 2)
plt.scatter(range(len(dual_coefs_gwo)), dual_coefs_gwo,
           c=dual_coefs_gwo, cmap='coolwarm', alpha=0.6, s=10)
plt.xlabel('Support Vector Index', fontsize=11, fontweight='bold')
plt.ylabel('Beta Coefficient Value', fontsize=11, fontweight='bold')
plt.title('Beta Coefficients by Support Vector', fontsize=12, fontweight='bold')
plt.axhline(y=0, color='black', linestyle='--', linewidth=1.5)
plt.colorbar(label='β_i value')
plt.grid(True, linestyle='--', alpha=0.5)

plt.tight_layout()
plt.savefig('beta_coefficients_analysis_gwo.png', dpi=300, bbox_inches='tight')
plt.show()

print("\nBeta coefficient analysis plot saved as 'beta_coefficients_analysis_gwo.png'")

# Export beta coefficients to Excel
print("\n" + "="*80)
print("EXPORTING BETA COEFFICIENTS TO EXCEL")
print("="*80)

beta_df = pd.DataFrame({
    'Support_Vector_Index': range(1, len(dual_coefs_gwo) + 1),
    'Beta_Coefficient': dual_coefs_gwo,
    'Absolute_Value': np.abs(dual_coefs_gwo),
    'Sign': ['Positive' if x > 0 else 'Negative' if x < 0 else 'Zero' for x in dual_coefs_gwo]
})

beta_df.to_excel('beta_coefficients_gwo.xlsx', index=False)
print("Beta coefficients exported to 'beta_coefficients_gwo.xlsx'")
print(f"Total rows exported: {len(beta_df)}")

# Summary statistics table
summary_stats = pd.DataFrame({
    'Statistic': ['Count', 'Mean', 'Std Dev', 'Min', 'Max', 'Sum', 'Positive Count', 'Negative Count'],
    'Value': [
        len(dual_coefs_gwo),
        dual_coefs_gwo.mean(),
        dual_coefs_gwo.std(),
        dual_coefs_gwo.min(),
        dual_coefs_gwo.max(),
        dual_coefs_gwo.sum(),
        n_positive,
        n_negative
    ]
})

print("\nBeta Coefficient Summary Statistics:")
print(summary_stats.to_string(index=False))
print("="*80)

# =====================================================
# EVALUASI MODEL PADA DATA TESTING
# =====================================================
print("\n" + "="*80)
print("EVALUASI MODEL PADA DATA TESTING")
print("="*80)

# Predict training data
train_pred_scaled = model_gwo.predict(X_train_scaled)
train_pred_inv = scaler_y.inverse_transform(train_pred_scaled.reshape(-1, 1))
y_train_inv = scaler_y.inverse_transform(y_train_scaled)

# Predict test data
test_pred_scaled = model_gwo.predict(X_test_scaled)
test_pred_inv = scaler_y.inverse_transform(test_pred_scaled.reshape(-1, 1))
y_test_inv = scaler_y.inverse_transform(y_test_scaled)

# Calculate MAPE
mape_train_gwo = mean_absolute_percentage_error(y_train_inv, train_pred_inv) * 100
mape_test_gwo = mean_absolute_percentage_error(y_test_inv, test_pred_inv) * 100

# Evaluasi data train
mse_train_gwo = mean_squared_error(y_train_inv, train_pred_inv)
rmse_train_gwo = np.sqrt(mse_train_gwo)
r2_train_gwo = r2_score(y_train_inv, train_pred_inv)

# Evaluasi data testing
mse_test_gwo = mean_squared_error(y_test_inv, test_pred_inv)
rmse_test_gwo = np.sqrt(mse_test_gwo)
r2_test_gwo = r2_score(y_test_inv, test_pred_inv)

print("\nPERFORMANCE METRICS - TRAINING DATA:")
print(f"  MSE   : {mse_train_gwo:.4f}")
print(f"  RMSE  : {rmse_train_gwo:.4f}")
print(f"  MAPE  : {mape_train_gwo:.4f}%")
print(f"  R²    : {r2_train_gwo:.4f}")

print("\nPERFORMANCE METRICS - TESTING DATA:")
print(f"  MSE   : {mse_test_gwo:.4f}")
print(f"  RMSE  : {rmse_test_gwo:.4f}")
print(f"  MAPE  : {mape_test_gwo:.4f}%")
print(f"  R²    : {r2_test_gwo:.4f}")
print("="*80)

# =====================================================
# PERBANDINGAN NILAI AKTUAL VS PREDIKSI
# =====================================================
split_idx = len(y_train)

df_train_pred = pd.DataFrame({
    'Date': df['Date'].iloc[:split_idx],
    'Aktual': y_train_inv.flatten(),
    'Prediksi': train_pred_inv.flatten()
})

df_test_pred = pd.DataFrame({
    'Date': df['Date'].iloc[split_idx:],
    'Aktual': y_test_inv.flatten(),
    'Prediksi': test_pred_inv.flatten()
})

print("\n" + "="*80)
print("SAMPLE PREDIKSI - TRAINING DATA (5 pertama):")
print("="*80)
print(df_train_pred.head().to_string(index=False))

print("\n" + "="*80)
print("SAMPLE PREDIKSI - TESTING DATA (5 pertama):")
print("="*80)
print(df_test_pred.head().to_string(index=False))

print("\n" + "="*80)
print("SAMPLE PREDIKSI - TESTING DATA (5 terakhir):")
print("="*80)
print(df_test_pred.tail().to_string(index=False))

# =====================================================
# PLOT ACTUAL VS PREDICTED
# =====================================================
plt.figure(figsize=(20, 10))
plt.scatter(df_train_pred['Date'], df_train_pred['Aktual'],
           label='Aktual Training', alpha=0.6, s=50, color='blue')
plt.plot(df_train_pred['Date'], df_train_pred['Prediksi'],
        'r--', label='Prediksi Training', linewidth=2)
plt.scatter(df_test_pred['Date'], df_test_pred['Aktual'],
           color='green', label='Aktual Testing', alpha=0.6, s=50)
plt.plot(df_test_pred['Date'], df_test_pred['Prediksi'],
        'orange', linestyle='--', label='Prediksi Testing', linewidth=2)
plt.ylabel('Harga Penutupan Saham ASII (Rp)', fontsize=12, fontweight='bold')
plt.xlabel('Date', fontsize=12, fontweight='bold')
plt.legend(loc='best', fontsize=11)
plt.title('Perbandingan Harga Saham Aktual vs Prediksi (SVR-GWO)',
         fontsize=14, fontweight='bold')
plt.grid(True, linestyle='--', alpha=0.7)
plt.tight_layout()
plt.savefig('svr_plot_gwo_complete.png', dpi=300, bbox_inches='tight')
plt.show()

print("\nPlot saved as 'svr_plot_gwo_complete.png'")

# =====================================================
# LEARNING CURVE
# =====================================================
print("\n" + "="*80)
print("GENERATING LEARNING CURVE...")
print("="*80)

train_sizes_lc, train_scores_lc, test_scores_lc = learning_curve(
    model_gwo, X_train_scaled, y_train_scaled.ravel(), cv=10,
    scoring='neg_mean_squared_error',
    train_sizes=np.linspace(0.1, 1.0, 10), random_state=42
)

train_scores_mean = -np.mean(train_scores_lc, axis=1)
train_scores_std = np.std(train_scores_lc, axis=1)
test_scores_mean = -np.mean(test_scores_lc, axis=1)
test_scores_std = np.std(test_scores_lc, axis=1)

plt.figure(figsize=(10, 6))
plt.title("Learning Curve for SVR-GWO", fontsize=14, fontweight='bold')
plt.xlabel("Training Set Size", fontsize=12, fontweight='bold')
plt.ylabel("Mean Squared Error", fontsize=12, fontweight='bold')

plt.plot(train_sizes_lc, train_scores_mean, 'o-', color="r",
        label="Training score", linewidth=2)
plt.fill_between(train_sizes_lc, train_scores_mean - train_scores_std,
                 train_scores_mean + train_scores_std, alpha=0.1, color="r")

plt.plot(train_sizes_lc, test_scores_mean, 'o-', color="g",
        label="Cross-validation score", linewidth=2)
plt.fill_between(train_sizes_lc, test_scores_mean - test_scores_std,
                 test_scores_mean + test_scores_std, alpha=0.1, color="g")

plt.legend(loc="best", fontsize=11)
plt.grid(True, linestyle='--', alpha=0.7)
plt.tight_layout()
plt.savefig('learning_curve_gwo_complete.png', dpi=300, bbox_inches='tight')
plt.show()

print("Learning curve saved as 'learning_curve_gwo_complete.png'")

# =====================================================
# RINGKASAN LENGKAP SEMUA TAHAP
# =====================================================
print("\n" + "="*80)
print("RINGKASAN LENGKAP PROSES SVR-GWO")
print("="*80)

print("\n1. EVALUASI UKURAN POPULASI:")
print("-" * 80)
popsize_summary = pd.DataFrame([
    {
        'Popsize': p['popsize'],
        'MAPE (%)': f"{p['mape']:.4f}",
        'Fitness': f"{p['fitness']:.8f}"
    }
    for p in popsize_results
])
print(popsize_summary.to_string(index=False))
print(f"\n   → Popsize Terbaik: {optimal_popsize}")

print("\n2. EVALUASI JUMLAH ITERASI:")
print("-" * 80)
iter_summary = pd.DataFrame([
    {
        'Max Iter': p['max_iter'],
        'MAPE (%)': f"{p['mape']:.4f}",
        'Fitness': f"{p['fitness']:.8f}"
    }
    for p in iteration_results
])
print(iter_summary.to_string(index=False))
print(f"\n   → Max Iter Terbaik: {optimal_max_iter}")

print("\n3. PARAMETER OPTIMAL FINAL:")
print("-" * 80)
print(f"   C       : {best_solution[0]:.6f}")
print(f"   Epsilon : {best_solution[1]:.6f}")
print(f"   Gamma   : {best_solution[2]:.6f}")
print(f"   Fitness : {best_fitness:.8f}")
print(f"   MAPE    : {mape_test_gwo:.4f}%")

print("\n4. PERFORMA MODEL:")
print("-" * 80)
print(f"   Training MAPE   : {mape_train_gwo:.4f}%")
print(f"   Testing MAPE    : {mape_test_gwo:.4f}%")
print(f"   Testing R²      : {r2_test_gwo:.4f}")
print(f"   Training Time   : {runtime:.3f} seconds")

print("\n" + "="*80)
print("PROSES SVR-GWO SELESAI! ✓")
print("="*80)

# =====================================================
# Perbandingan Kinerja
# =====================================================

def compare_models(mape_without_opt, mape_with_gwo):
    print("\n" + "="*60)
    print("PERBANDINGAN KINERJA MODEL")
    print("="*60)
    print(f"MAPE Default (tanpa optimasi): {mape_without_opt:.4f}%")
    print(f"MAPE dengan GWO Optimization : {mape_with_gwo:.4f}%")
    print("="*60)

    # Calculate improvement
    improvement_gwo = ((mape_without_opt - mape_with_gwo) / mape_without_opt) * 100

    print("\nPERBANDINGAN PENINGKATAN:")
    print(f"Peningkatan GWO vs Default: {improvement_gwo:.2f}%")

    if mape_with_gwo < mape_without_opt:
        print(f"\n\u2713 Model GWO lebih baik {improvement_gwo:.2f}% dari model default")
    else:
        print(f"\n\u2718 Model default lebih baik {-improvement_gwo:.2f}% dari model GWO")

    print("="*60)

    # Determine best model
    if mape_with_gwo < mape_without_opt:
        print("\nKESIMPULAN:")
        print("Model dengan optimasi GWO memberikan performa terbaik")
        return 'gwo'
    else:
        print("\nKESIMPULAN:")
        print("Model default memberikan performa terbaik")
        return 'default'

# Call comparison function
best_model_type = compare_models(mape_test_default, mape_gwo_final)

# =====================================================
# Peramalan 15 Periode ke Depan
# =====================================================

import pandas as pd
import datetime
from pandas.tseries.holiday import AbstractHolidayCalendar, Holiday
from sklearn.svm import SVR
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import numpy as np
import matplotlib.pyplot as plt

# Load the dataset (re-added for cell independence)
url = 'https://raw.githubusercontent.com/dyahprimasarii/Data-Saham/refs/heads/main/Harga%20Penutupan%20ASII'
df = pd.read_csv(url)

# Ubah tipe data kolom tanggal menjadi datetime (re-added for cell independence)
df['Date'] = pd.to_datetime(df['Date'], format='%d/%m/%Y')

# Membuat lag 1 (re-added for cell independence)
df['lag1'] = df['Close'].shift(1)
# Drop missing values dari lag (re-added for cell independence)
df = df.dropna()

# Re-establish X and y from the df loaded in this cell
X = df[['lag1']].values
y = df['Close'].values

# Re-establish train/test split (as done in 2f18cb64-ff3f-4e8f-a154-6e8ee92d218d)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=False)

# Re-initialize and fit scalers (as done in 47ff7b73-ca26-4394-b666-0246d0f9d5d5)
scaler_x = StandardScaler()
scaler_y = StandardScaler()
X_train_scaled = scaler_x.fit_transform(X_train)
y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1))

# Hardcode best_solution values from the output of GWO (cell 558f922a-e579-4b97-83ab-92e7261c5de1)
# C: 99.246896
# Epsilon: 0.269625
# Gamma: 12.231004
best_solution_hardcoded = [99.246896, 0.269625, 12.231004]

# Re-initialize and fit model_gwo (as done in OB6CoHPPgZQ0)
model_gwo = SVR(C=best_solution_hardcoded[0],
                epsilon=best_solution_hardcoded[1],
                gamma=best_solution_hardcoded[2])
model_gwo.fit(X_train_scaled, y_train_scaled.ravel())

# Definisi calendar untuk hari libur
class HolidayCalendar(AbstractHolidayCalendar):
    rules = [
        Holiday('New Year Eve', month=12, day=31),
        Holiday('New Year', month=1, day=1),
        Holiday('Christmas', month=12, day=25)
    ]

def generate_forecast_dates(last_date, n_days=15):
    """
    Generate business days for forecasting, excluding holidays
    """
    calendar = HolidayCalendar()
    holidays = calendar.holidays(start=last_date,
                                 end=last_date + datetime.timedelta(days=365))

    forecast_dates = []
    current_date = last_date

    while len(forecast_dates) < n_days:
        current_date += datetime.timedelta(days=1)
        if current_date.weekday() < 5 and current_date not in holidays:
            forecast_dates.append(current_date)

    return forecast_dates

def generate_forecast(model, df, scaler_X_local, scaler_y_local, n_days=15):
    """
    Generate forecast dengan trend adjustment
    """
    last_date = pd.to_datetime(df['Date']).iloc[-1]
    forecast_dates = generate_forecast_dates(last_date, n_days)

    # Hitung trend historis (rata-rata perubahan harian 30 hari terakhir)
    recent_data = df['Close'].tail(30)
    daily_changes = recent_data.diff().dropna()
    avg_trend = daily_changes.mean()

    # Ambil nilai terakhir
    last_value = df['Close'].iloc[-1]
    current_value = last_value

    forecasts = []

    for i in range(n_days):
        # Scale input
        lag_scaled = scaler_X_local.transform([[current_value]])[0][0]

        # Prediksi
        prediction_scaled = model.predict([[lag_scaled]])[0]
        prediction = scaler_y_local.inverse_transform([[prediction_scaled]])[0][0]

        # Tambahkan trend adjustment (20% dari trend historis)
        trend_adjusted = prediction + (0.2 * avg_trend)

        # Slight smoothing (80% prediction, 20% previous)
        final_prediction = 0.8 * trend_adjusted + 0.2 * current_value

        forecasts.append(final_prediction)
        current_value = final_prediction

    forecast_df = pd.DataFrame({
        'Date': forecast_dates,
        'Forecast': forecasts
    })

    return forecast_df

# Generate forecast
forecast_df = generate_forecast(model_gwo, df, scaler_x, scaler_y, n_days=15)

# Forecast error estimation
forecast_error = df['Close'].tail(15).std()
print(f"\nExpected Forecast Error Range: \u00b1Rp {forecast_error:.2f}")

# Print forecast results
print("\n15-DAY FORECAST (EXCLUDING WEEKENDS AND HOLIDAYS):")
print(forecast_df.to_string(index=False))

# Forecast summary statistics
print("\n" + "="*60)
print("FORECAST SUMMARY STATISTICS")
print("="*60)
print(f"Starting Price    : Rp {forecast_df['Forecast'].iloc[0]:,.2f}")
print(f"Ending Price      : Rp {forecast_df['Forecast'].iloc[-1]:,.2f}")
print(f"Total Change      : Rp {(forecast_df['Forecast'].iloc[-1] - forecast_df['Forecast'].iloc[0]):,.2f}")
print(f"Percentage Change : {((forecast_df['Forecast'].iloc[-1] - forecast_df['Forecast'].iloc[0])/forecast_df['Forecast'].iloc[0]*100):.2f}%")
print(f"Average Price     : Rp {forecast_df['Forecast'].mean():,.2f}")
print(f"Highest Price     : Rp {forecast_df['Forecast'].max():,.2f}")
print(f"Lowest Price      : Rp {forecast_df['Forecast'].min():,.2f}")
print("="*60)

# =====================================================
# VISUALISASI HASIL PERAMALAN
# =====================================================

# Plot 1: Forecast Only
plt.figure(figsize=(14, 7))
plt.plot(forecast_df['Date'], forecast_df['Forecast'],
         label='Forecast (SVR-GWO)', color='blue', marker='o',
         linestyle='--', linewidth=2, markersize=8)

plt.title('15-Day Stock Price Forecast (SVR-GWO)',
          fontsize=16, fontweight='bold', pad=20)
plt.xlabel('Date', fontsize=13, fontweight='bold')
plt.ylabel('Forecasted Price (Rp)', fontsize=13, fontweight='bold')
plt.grid(True, linestyle='--', alpha=0.7)
plt.xticks(rotation=45, ha='right')
plt.tight_layout()

# Add value labels
for i, row in forecast_df.iterrows():
    plt.text(row['Date'], row['Forecast'], f"Rp {row['Forecast']:,.0f}",
             ha='center', va='bottom', fontsize=8, fontweight='bold')

plt.legend(loc='best', fontsize=11)
plt.savefig('plot_forecast_15_days.png', dpi=300, bbox_inches='tight')
plt.show()

print("\nForecast plot saved as 'plot_forecast_15_days.png'")

# Plot 2: Historical + Forecast
plt.figure(figsize=(16, 8))

historical_data = df.tail(60).copy()
plt.plot(historical_data['Date'], historical_data['Close'],
         label='Historical Data', color='steelblue', linewidth=2)

plt.plot(forecast_df['Date'], forecast_df['Forecast'],
         label='Forecast (SVR-GWO)', color='red', marker='o',
         linestyle='--', linewidth=2.5, markersize=8)

last_date = df['Date'].iloc[-1]
plt.axvline(x=last_date, color='green', linestyle=':', linewidth=2,
            label='Forecast Start')

plt.title('Historical Data vs 15-Day Forecast (SVR-GWO)',
          fontsize=16, fontweight='bold', pad=20)
plt.xlabel('Date', fontsize=13, fontweight='bold')
plt.ylabel('Stock Price (Rp)', fontsize=13, fontweight='bold')
plt.grid(True, linestyle='--', alpha=0.7)
plt.xticks(rotation=45, ha='right')
plt.legend(loc='best', fontsize=11)
plt.tight_layout()
plt.savefig('plot_historical_vs_forecast.png', dpi=300, bbox_inches='tight')
plt.show()

print("Historical vs Forecast plot saved as 'plot_historical_vs_forecast.png'")